{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PPMI.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1nsFOChmi7FqcJ-V-mjk-K8eB2PFiC8Um","authorship_tag":"ABX9TyOujUySdHOxES98C8bGnaXj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGittLa6QZ_V","executionInfo":{"status":"ok","timestamp":1655234417044,"user_tz":-330,"elapsed":5624,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}},"outputId":"c1f8ace3-6690-4a2c-84ff-72789e670283"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting texthero\n","  Downloading texthero-1.1.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.3.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.21.6)\n","Requirement already satisfied: gensim<4.0,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.6.0)\n","Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (4.64.0)\n","Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.2.2)\n","Collecting unidecode>=1.1.1\n","  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 6.7 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.0.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (2.2.4)\n","Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (5.5.0)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.0.2)\n","Requirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from texthero) (1.5.0)\n","Requirement already satisfied: nltk>=3.3 in /usr/local/lib/python3.7/dist-packages (from texthero) (3.7)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.15.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0,>=3.6.0->texthero) (6.0.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->texthero) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.0->texthero) (4.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (2022.6.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.2->texthero) (2022.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.2.0->texthero) (8.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->texthero) (3.1.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.4.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (7.4.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (57.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (0.9.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.7)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (2.23.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (3.0.6)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0->texthero) (1.0.5)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0->texthero) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0->texthero) (2022.5.18.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud>=1.5.0->texthero) (7.1.2)\n","Installing collected packages: unidecode, texthero\n","Successfully installed texthero-1.1.0 unidecode-1.3.4\n"]}],"source":["!pip install texthero"]},{"cell_type":"code","source":["import nltk\n","from nltk.collocations import *\n","import texthero as hero\n","import pandas as pd\n","import itertools\n","import numpy as np \n","from nltk import bigrams \n","from nltk.corpus import inaugural\n","nltk.download('genesis')\n","nltk.download('inaugural')\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uwFtmM4HQaqr","executionInfo":{"status":"ok","timestamp":1655234423934,"user_tz":-330,"elapsed":6903,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}},"outputId":"8dd59159-f07f-4c91-f0f2-31a6e63fe447"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package genesis to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/genesis.zip.\n","[nltk_data] Downloading package inaugural to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/inaugural.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["print(\"Number of words\",len(inaugural.words(\"/content/drive/MyDrive/Colab Notebooks/NLP/mughal.txt\")))\n","corpus=(inaugural.words(\"/content/drive/MyDrive/Colab Notebooks/NLP/mughal.txt\"))\n","print(corpus)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWHo9WP6VOhv","executionInfo":{"status":"ok","timestamp":1655234485358,"user_tz":-330,"elapsed":818,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}},"outputId":"40610caf-a1e1-4ad2-b6fd-20211adc0630"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words 24104\n","['Mughal', 'Empire', 'From', 'Wikipedia', ',', 'the', ...]\n"]}]},{"cell_type":"markdown","source":["Text Processing"],"metadata":{"id":"U4UgxD_MuH9p"}},{"cell_type":"code","source":["corpus=pd.Series(corpus)\n","corpus=hero.remove_punctuation(corpus)   #Remove all string.punctuation (!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~).\n","corpus=hero.remove_diacritics(corpus)    #Remove all accentuated characters from strings.\n","corpus=hero.remove_stopwords(corpus)      #Remove all stop words.\n","corpus=hero.remove_whitespace(corpus)    #Remove whitespace\n","corpus=hero.lowercase(corpus)              #Lowercase all text.\n","corpus=hero.remove_digits(corpus)         #Remove all blocks of digits.\n"],"metadata":{"id":"vRa01CdTWIxW","executionInfo":{"status":"ok","timestamp":1655234488245,"user_tz":-330,"elapsed":393,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Top 50 bigrams"],"metadata":{"id":"_6AhlRyQqNoO"}},{"cell_type":"code","source":["bigram_measures = nltk.collocations.BigramAssocMeasures()\n","finder = BigramCollocationFinder.from_words(corpus)\n","finder.nbest(bigram_measures.pmi, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpkcxREDQeNk","executionInfo":{"status":"ok","timestamp":1655234491994,"user_tz":-330,"elapsed":594,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}},"outputId":"3381373f-8eaf-483f-f9cc-61fcdf12e982"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('abhishek', 'kaicker'),\n"," ('abjuring', 'liquor'),\n"," ('adroitly', 'gave'),\n"," ('aerial', 'view'),\n"," ('aerospace', 'laboratories'),\n"," ('afghanistanmedieval', 'indiahistorical'),\n"," ('aggregated', 'millet'),\n"," ('aggrieved', 'subject'),\n"," ('allowed', 'freedom'),\n"," ('american', 'ethnologist'),\n"," ('amir', 'khusrau'),\n"," ('ancient', 'greece'),\n"," ('and', 'designing'),\n"," ('articletalk', 'readview'),\n"," ('ashok', 'desai'),\n"," ('assamese', 'highlands'),\n"," ('assesses', 'ship'),\n"," ('attracting', '7a'),\n"," ('autumn', 'festivals'),\n"," ('banarsi', 'prasad'),\n"," ('best', 'guidance'),\n"," ('beyond', 'repair'),\n"," ('bibi', 'ka'),\n"," ('boo', 'rods'),\n"," ('brass', 'utensils'),\n"," ('brother', 'gommans'),\n"," ('cadastral', 'surveying'),\n"," ('chandrika', 'kaul'),\n"," ('chapai', 'nawabganj'),\n"," ('chroniclers', 'bewailed'),\n"," ('claimed', 'ultimate'),\n"," ('colin', 'mcevedy'),\n"," ('concerning', 'mankind'),\n"," ('continual', 'pacification'),\n"," ('contraction', 'patterns'),\n"," ('contribute', 'help'),\n"," ('conventionally', 'reckoned'),\n"," ('corps', 'consisting'),\n"," ('courtier', 'wearing'),\n"," ('crop', 'yields'),\n"," ('cultivators', 'begun'),\n"," ('current', 'events'),\n"," ('decorative', 'borders'),\n"," ('demographic', 'upsurge'),\n"," ('der', 'meij'),\n"," ('dia', 'britannica'),\n"," ('diplomatic', 'ties'),\n"," ('distribute', 'assignments'),\n"," ('donate', 'contribute'),\n"," ('draw', 'bar')]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["def pmi(df):\n","    '''\n","    Calculate the positive pointwise mutal information score for each entry\n","    https://en.wikipedia.org/wiki/Pointwise_mutual_information\n","    We use the log( p(y|x)/p(y) ), y being the column, x being the row\n","    '''\n","    # Get numpy array from pandas df\n","    #arr = df.as_matrix()\n","    arr=np.array(df)\n","    # p(y|x) probability of each t1 overlap within the row\n","    row_totals = arr.sum(axis=1).astype(float)\n","    prob_cols_given_row = (arr.T / row_totals).T\n","\n","    # p(y) probability of each t1 in the total set\n","    col_totals = arr.sum(axis=0).astype(float)\n","    prob_of_cols = col_totals / sum(col_totals)\n","\n","    # PMI: log( p(y|x) / p(y) )\n","    # This is the same data, normalized\n","    ratio = prob_cols_given_row / prob_of_cols\n","    ratio[ratio==0] = 0.00001\n","    _pmi = np.log(ratio)\n","    _pmi[_pmi < 0] = 0\n","\n","    return _pmi\n"],"metadata":{"id":"BvcH3OkzUKqK","executionInfo":{"status":"ok","timestamp":1655235414487,"user_tz":-330,"elapsed":352,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["   \n","\n","def co_occurrence_matrix(corpus):\n","    vocab = set(corpus)\n","    vocab = list(vocab)\n","\n","    # Key:Value = Word:Index\n","    vocab_to_index = { word:i for i, word in enumerate(vocab) }\n","\n","    # Create bigrams from all words in corpus\n","    bi_grams = list(bigrams(corpus))\n","\n","    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n","    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n","\n","    # Initialise co-occurrence matrix\n","    # co_occurrence_matrix[current][previous]\n","    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n","\n","    # Loop through the bigrams in the frequency distribution, noting the \n","    # current and previous word, and the number of occurrences of the bigram.\n","    # Get the vocab index of the current and previous words.\n","    # Put the number of occurrences into the appropriate element of the array.\n","    for bigram in bigram_freq:\n","        current = bigram[0][1]\n","        previous = bigram[0][0]\n","        count = bigram[1]\n","        pos_current = vocab_to_index[current]\n","        pos_previous = vocab_to_index[previous]\n","        co_occurrence_matrix[pos_current][pos_previous] = count \n","\n","    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n","\n","    return co_occurrence_matrix\n","\n","test_sent =finder.nbest(bigram_measures.pmi,10)\n","m = co_occurrence_matrix(corpus)"],"metadata":{"id":"hMiJIh56WftS","executionInfo":{"status":"ok","timestamp":1655235368100,"user_tz":-330,"elapsed":643,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(m)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkX9fBK0Y0ox","executionInfo":{"status":"ok","timestamp":1655235372029,"user_tz":-330,"elapsed":358,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}},"outputId":"928870f7-ab78-41be-e448-2cf3f03c277d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.03e+03 1.00e+00 0.00e+00 ... 0.00e+00 1.00e+00 2.00e+00]\n"," [1.00e+00 0.00e+00 0.00e+00 ... 0.00e+00 0.00e+00 0.00e+00]\n"," [1.00e+00 0.00e+00 0.00e+00 ... 0.00e+00 0.00e+00 0.00e+00]\n"," ...\n"," [0.00e+00 0.00e+00 0.00e+00 ... 0.00e+00 0.00e+00 0.00e+00]\n"," [1.00e+00 0.00e+00 0.00e+00 ... 0.00e+00 0.00e+00 0.00e+00]\n"," [1.00e+00 0.00e+00 0.00e+00 ... 0.00e+00 0.00e+00 0.00e+00]]\n"]}]},{"cell_type":"markdown","source":["PPMI"],"metadata":{"id":"rPGVBOUEuWZw"}},{"cell_type":"code","source":["PPMI=pmi(m)\n","print(PPMI)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YH03TXeBY2Q1","executionInfo":{"status":"ok","timestamp":1655235419099,"user_tz":-330,"elapsed":932,"user":{"displayName":"TIJU GEORGE VARGHESE","userId":"08809546471591937227"}},"outputId":"2c64ca9d-ae10-49d4-a880-2a11868e0188"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.         0.86427165 0.         ... 0.         0.86427165 0.86427165]\n"," [0.86437012 0.         0.         ... 0.         0.         0.        ]\n"," [0.17122294 0.         0.         ... 0.         0.         0.        ]\n"," ...\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.86437012 0.         0.         ... 0.         0.         0.        ]\n"," [0.17122294 0.         0.         ... 0.         0.         0.        ]]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"0y5ScHopaLLO"},"execution_count":null,"outputs":[]}]}